{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import datetime as dt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ivytong/H1B Dashboard'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_columns_20212020 = ['CASE_NUMBER', 'CASE_STATUS','DECISION_DATE', 'VISA_CLASS', 'JOB_TITLE', 'SOC_CODE',\n",
    "       'SOC_TITLE','EMPLOYER_NAME','NAICS_CODE','LAWFIRM_NAME_BUSINESS_NAME','WORKSITE_CITY',\n",
    "       'WORKSITE_STATE', 'WORKSITE_POSTAL_CODE', 'WAGE_RATE_OF_PAY_FROM',\n",
    "       'WAGE_RATE_OF_PAY_TO', 'WAGE_UNIT_OF_PAY', 'PREVAILING_WAGE',\n",
    "       'PW_UNIT_OF_PAY', 'PW_WAGE_LEVEL', 'PW_OES_YEAR','PW_OTHER_SOURCE']\n",
    "\n",
    "use_columns_2019 = ['CASE_NUMBER', 'CASE_STATUS','DECISION_DATE', 'VISA_CLASS', 'JOB_TITLE', 'SOC_CODE',\n",
    "       'SOC_TITLE','EMPLOYER_NAME','NAICS_CODE', 'AGENT_ATTORNEY_LAW_FIRM_BUSINESS_NAME', 'WORKSITE_CITY_1',\n",
    "        'WORKSITE_STATE_1','WORKSITE_POSTAL_CODE_1','WAGE_RATE_OF_PAY_FROM_1', \n",
    "        'WAGE_RATE_OF_PAY_TO_1', 'WAGE_UNIT_OF_PAY_1', 'PREVAILING_WAGE_1', \n",
    "        'PW_UNIT_OF_PAY_1', 'PW_WAGE_LEVEL_1', 'PW_OES_YEAR_1', 'PW_OTHER_SOURCE_1']\n",
    "\n",
    "use_columns_20182017 = ['CASE_NUMBER', 'CASE_STATUS','DECISION_DATE', 'VISA_CLASS', 'JOB_TITLE', 'SOC_CODE',\n",
    "       'SOC_NAME','EMPLOYER_NAME','NAICS_CODE','AGENT_ATTORNEY_NAME','WORKSITE_CITY', \n",
    "       'WORKSITE_STATE', 'WORKSITE_POSTAL_CODE', 'WAGE_RATE_OF_PAY_FROM',\n",
    "       'WAGE_RATE_OF_PAY_TO', 'WAGE_UNIT_OF_PAY', 'PREVAILING_WAGE',\n",
    "       'PW_UNIT_OF_PAY', 'PW_WAGE_LEVEL', 'PW_SOURCE_YEAR','PW_SOURCE']\n",
    "\n",
    "# df.columns[np.r_[4,35,36,85,96,97,98]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/Users/ivytong/H1B Dashboard/Data/Final/FY2021.csv', usecols = use_columns_20212020)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define a number of functions to clean the data\n",
    "'''\n",
    "\n",
    "def clean_zip_code(zipcode):\n",
    "    return re.sub('[^0-9]','', zipcode)[:5]\n",
    "\n",
    "\n",
    "def clean_code(code):\n",
    "    return code.split('.')[0][:7]\n",
    "\n",
    "def clean_title(title):\n",
    "    step1 = re.sub('[^A-Za-z\\s]','', title.strip())\n",
    "    step2 = re.sub('[Ss]$','', step1.strip())\n",
    "    final_title = re.sub('\\s+',' ', step2.strip())\n",
    "    return final_title.upper().title().strip()\n",
    "\n",
    "STATE_ABBREV_LOOKUP = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "def get_state_abbrev(state):\n",
    "    if len(state) == 2:\n",
    "        return state.upper()\n",
    "    elif state.lower().title().replace('The','').strip() in STATE_ABBREV_LOOKUP:\n",
    "        return STATE_ABBREV_LOOKUP[state.lower().title()]   \n",
    "    else:\n",
    "        return 'No Info'\n",
    "    \n",
    "RE_CITY = re.compile(r\"^([a-zA-Z\\']+(\\.|\\,)(\\s?|\\-))?(([a-zA-Z\\']+(\\s+|\\-))*)([a-zA-Z\\']+)$\")\n",
    "def clean_city(city):\n",
    "    step1 = city.replace(',','')\n",
    "    step2 = step1.replace('&nbsp','')\n",
    "    step3 = step2.replace('D.C.','')\n",
    "    result = RE_CITY.search(step3.strip())\n",
    "    if result:\n",
    "        return result[0].title()\n",
    "    return 'No Info'\n",
    "\n",
    "\n",
    "# wage_unit_conversion = {\n",
    "#     'Year': 1,\n",
    "#     \"Month\" : 12, \n",
    "#     \"Hour\" : 2080,\n",
    "#     \"Bi-Weekly\" : 26,\n",
    "#     \"Week\" : 52,\n",
    "#     np.nan:1\n",
    "# }\n",
    "# def get_wage_unit(wage_unit):\n",
    "#     return wage_unit_conversion[wage_unit]\n",
    "\n",
    "hour_unit_conversion = {\n",
    "    'Year': 2080,\n",
    "    \"Month\" : 175, #2080/12\n",
    "    \"Hour\" : 1,\n",
    "    \"Bi-Weekly\" : 80,\n",
    "    \"Week\" : 40,\n",
    "    np.nan : 2080\n",
    "}\n",
    "\n",
    "def get_wage_unit(wage_unit):\n",
    "    return hour_unit_conversion[wage_unit]\n",
    "\n",
    "def get_hourly_wage(wage_per_hour):\n",
    "    if wage_per_hour >=7.25 and wage_per_hour <= 3500:\n",
    "        return wage_per_hour    \n",
    "    return 7.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_name_replace(company_name,n):\n",
    "    def internal(string):\n",
    "        string = company_name.lower().strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)p(\\.)?l(\\.)?l(\\.)?c(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)p(\\.)?l(\\.)?c(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)l(\\.)?l(\\.)?c(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)l(\\.)?p(\\.)?a(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)a(\\.)?p(\\.)?c(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)l(\\.)?l(\\.)?p(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)l(\\.)?l(\\.)?o(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)l(\\.)?c(\\.)?c(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)u(\\.)?s(\\.)?a(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)inc(\\.)?($|\\W)', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)corp(\\.)?($|\\W)', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)assc(\\.)?($|\\W)', ' associates', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)l(\\.)?t(\\.)?d(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)l(\\.)?p(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)p(\\.)?a(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)p(\\.)?c(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\,\\s*|\\s+)o(\\.)?d(\\.)?$', '', string).strip()\n",
    "        string = re.sub(r'(\\(:.;(/)+-=*(\\)`|$))', '', string).strip()\n",
    "        string = re.sub(r'\\.$', '', string).strip()\n",
    "        string = re.sub(r'\\-', ' ', string).strip()\n",
    "        string = re.sub(r'[\\?]*[\\|]*[\\/]*', '', string).strip()\n",
    "        string = re.sub(r'\\\\*', '', string).strip()\n",
    "        string = re.sub(r'group$', '', string).strip()\n",
    "        string = re.sub(r'corporation$', '', string).strip()\n",
    "        string = re.sub(r'incorporated$', '', string).strip()\n",
    "        string = re.sub(r'office[s]*$', '', string).strip()\n",
    "        string = re.sub(r'firm[s]*$', '', string).strip()\n",
    "        string = re.sub(r'group$', '', string).strip()\n",
    "        string = re.sub(r'americas$', '', string).strip()\n",
    "        string = re.sub(r'\\s+us$', '', string).strip()\n",
    "        string = re.sub(r'\\&', 'and', string).strip()\n",
    "        string = re.sub(r'\\,\\s+and\\s+', ' and ', string).strip()\n",
    "        string = re.sub(r'\\s+([A-Za-z])\\.?\\s+', r' \\1. ', string)\n",
    "        string = re.sub(r'\\s+', ' ', string).strip()\n",
    "        string = re.sub(r'^[,]+$', 'No Info', string).strip()\n",
    "\n",
    "        return string.title().strip()\n",
    "    \n",
    "    result = company_name\n",
    "    for i in range(n):\n",
    "        result = internal(result)\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_20212020(data):\n",
    "    data['DECISION_DATE'] = data['DECISION_DATE'].dt.date\n",
    "    data['CASE_STATUS'] = data['CASE_STATUS'].str.lower().str.title()\n",
    "    data = data[(data['CASE_STATUS'] == \"Certified\") & ((data['VISA_CLASS']== 'H-1B')| (data['VISA_CLASS']== 'H-1B1 Chile')| (data['VISA_CLASS']== 'H-1B1 Singapore'))].drop_duplicates(subset=['CASE_NUMBER'])\n",
    "    \n",
    "    for x in ['EMPLOYER_NAME','LAWFIRM_NAME_BUSINESS_NAME','WORKSITE_CITY','WORKSITE_STATE','WORKSITE_POSTAL_CODE','JOB_TITLE','PW_WAGE_LEVEL',\n",
    "             'PW_OES_YEAR','PW_OTHER_SOURCE']:\n",
    "        data[x] = data[x].fillna('No Info')\n",
    "        \n",
    "    \n",
    "    data['SOC_CODE'] = data['SOC_CODE'].apply(lambda x : clean_code(x))\n",
    "    data['SOC_TITLE'] = data['SOC_TITLE'].apply(lambda x : clean_title(x))\n",
    "    data['NAICS_CODE'] = data['NAICS_CODE'].apply(lambda x : clean_code(str(x)))   \n",
    "    data['WORKSITE_STATE'] = data['WORKSITE_STATE'].apply(lambda x : get_state_abbrev(x))\n",
    "    data['WORKSITE_CITY'] = data['WORKSITE_CITY'].apply(lambda x : clean_city(x))\n",
    "    data['WORKSITE_POSTAL_CODE'] = data['WORKSITE_POSTAL_CODE'].apply(lambda x : clean_zip_code(x))   \n",
    "    data['WORKSITE_POSTAL_CODE'] = data['WORKSITE_POSTAL_CODE'].str.zfill(5)\n",
    "    \n",
    "    data['WAGE_UNIT'] =  data['WAGE_UNIT_OF_PAY'].apply(lambda x : get_wage_unit(x))\n",
    "    data['WAGE1_HOURLY_RATE'] = data['WAGE_RATE_OF_PAY_FROM'] / data['WAGE_UNIT']\n",
    "    data['WAGE2_HOURLY_RATE'] = data['WAGE_RATE_OF_PAY_TO'] / data['WAGE_UNIT']    \n",
    "    data['WAGE1'] = data['WAGE1_HOURLY_RATE'].apply(lambda x: get_hourly_wage(x) * 2080) \n",
    "    data['WAGE2'] = data['WAGE1_HOURLY_RATE'].apply(lambda x: get_hourly_wage(x) * 2080) \n",
    "    \n",
    "    data['ANNUAL_WAGE'] = data['WAGE2'] if data['WAGE1'].empty else data['WAGE1'] \n",
    "    data['PW_UNIT'] = data['PW_UNIT_OF_PAY'].apply(lambda x : get_wage_unit(x))\n",
    "    data['ANNUAL_PW_RATE'] = data['PREVAILING_WAGE'] / data['PW_UNIT']\n",
    "    data['ANNUAL_PW'] = data['ANNUAL_PW_RATE'].apply(lambda x : get_hourly_wage(x) * 2080)\n",
    "    \n",
    "    \n",
    "    data['JOB_TITLE'] = data['JOB_TITLE'].apply(lambda x : clean_title(x))\n",
    "    data['EMPLOYER'] = data['EMPLOYER_NAME'].apply(lambda x : company_name_replace(x,2))\n",
    "    data['EMPLOYER_2'] = data['EMPLOYER'] .apply(lambda x: 'Amazon' if 'Amazon' in x else x)\n",
    "#     data.loc[data['EMPLOYER'].str.contains('AMAZON', case= False), 'EMPLOYER'] = 'AMAZON'\n",
    "    data['AGENT_LAWFIRM'] = data['LAWFIRM_NAME_BUSINESS_NAME'].apply(lambda x : company_name_replace(x,2))\n",
    "    \n",
    "    stem_list = set(pd.read_excel('stem.xlsx')['OCC_CODE'])\n",
    "    data['STEM'] = data['SOC_CODE'].apply(lambda x : 1 if x in stem_list else 0)\n",
    "    data['SOC_CODE'] = data['SOC_CODE'].apply(lambda x : \"SOC \" + clean_code(x))\n",
    "    \n",
    "    data = data.drop(columns = ['CASE_NUMBER','WAGE_UNIT','WAGE1',\n",
    "                                'WAGE2','PW_UNIT_OF_PAY','PW_UNIT','PREVAILING_WAGE',\n",
    "                               'WAGE_RATE_OF_PAY_FROM','WAGE_RATE_OF_PAY_TO','WAGE_UNIT_OF_PAY','EMPLOYER_NAME','LAWFIRM_NAME_BUSINESS_NAME',\n",
    "                               'WAGE1_HOURLY_RATE','WAGE2_HOURLY_RATE','ANNUAL_PW_RATE'])\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "for file in glob.glob('Data/Final/FY202*.csv'):\n",
    "    filename = file.split('/')[-1]\n",
    "    df = pd.read_csv(file, usecols = use_columns_20212020,parse_dates=['DECISION_DATE'])\n",
    "    clean_data_20212020(df).to_csv(os.path.join(os.getcwd(),'Download/',filename), index = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_2019(data):\n",
    "    data['DECISION_DATE'] = data['DECISION_DATE'].dt.date\n",
    "    data['CASE_STATUS'] = data['CASE_STATUS'].str.lower().str.title()\n",
    "    data = data[(data['CASE_STATUS'] == \"Certified\") & ((data['VISA_CLASS']== 'H-1B')| (data['VISA_CLASS']== 'H-1B1 Chile')| (data['VISA_CLASS']== 'H-1B1 Singapore'))].drop_duplicates(subset=['CASE_NUMBER'])\n",
    "    \n",
    "    for x in ['EMPLOYER_NAME','AGENT_ATTORNEY_LAW_FIRM_BUSINESS_NAME','WORKSITE_CITY_1','WORKSITE_STATE_1','WORKSITE_POSTAL_CODE_1','JOB_TITLE']:\n",
    "        data[x] = data[x].fillna('No Info')\n",
    "    \n",
    "    data['PW_WAGE_LEVEL'] = data['PW_WAGE_LEVEL_1'].fillna('No Info')\n",
    "    data['PW_OES_YEAR'] = data['PW_OES_YEAR_1'].fillna('No Info')\n",
    "    data['PW_OTHER_SOURCE'] = data['PW_OTHER_SOURCE_1'].fillna('No Info')\n",
    "    \n",
    "    data['SOC_CODE'] = data['SOC_CODE'].apply(lambda x : clean_code(x))\n",
    "    data['SOC_TITLE'] = data['SOC_TITLE'].apply(lambda x : clean_title(x))\n",
    "    data['NAICS_CODE'] = data['NAICS_CODE'].apply(lambda x : clean_code(str(x)) ) \n",
    "    data['WORKSITE_STATE'] = data['WORKSITE_STATE_1'].apply(lambda x : get_state_abbrev(x))\n",
    "    data['WORKSITE_CITY'] = data['WORKSITE_CITY_1'].apply(lambda x : clean_city(x))\n",
    "    data['WORKSITE_POSTAL_CODE'] = data['WORKSITE_POSTAL_CODE_1'].apply(lambda x : clean_zip_code(x))   \n",
    "    data['WORKSITE_POSTAL_CODE'] = data['WORKSITE_POSTAL_CODE'].str.zfill(5)\n",
    "    \n",
    "    \n",
    "    data['WAGE_UNIT'] =  data['WAGE_UNIT_OF_PAY_1'].apply(lambda x : get_wage_unit(x))\n",
    "    data['WAGE1_HOURLY_RATE'] = data['WAGE_RATE_OF_PAY_FROM_1'] / data['WAGE_UNIT']\n",
    "    data['WAGE2_HOURLY_RATE'] = data['WAGE_RATE_OF_PAY_TO_1'] / data['WAGE_UNIT']\n",
    "    data['WAGE1'] = data['WAGE1_HOURLY_RATE'].apply(lambda x: get_hourly_wage(x)*2080) \n",
    "    data['WAGE2'] = data['WAGE1_HOURLY_RATE'].apply(lambda x: get_hourly_wage(x)*2080) \n",
    "    data['ANNUAL_WAGE'] = data['WAGE2'] if data['WAGE1'].empty else data['WAGE1'] \n",
    "    data['PW_UNIT'] = data['PW_UNIT_OF_PAY_1'].apply(lambda x : get_wage_unit(x))\n",
    "    data['ANNUAL_PW_RATE'] = data['PREVAILING_WAGE_1'] / data['PW_UNIT']\n",
    "    data['ANNUAL_PW'] = data['ANNUAL_PW_RATE'].apply(lambda x : get_hourly_wage(x)*2080)\n",
    " \n",
    " \n",
    "    \n",
    "    data['JOB_TITLE'] = data['JOB_TITLE'].apply(lambda x : clean_title(x))\n",
    "    data['EMPLOYER'] = data['EMPLOYER_NAME'].apply(lambda x : company_name_replace(x,2))\n",
    "    data['EMPLOYER_2'] = data['EMPLOYER'] .apply(lambda x: 'Amazon' if 'Amazon' in x else x)\n",
    "    data['AGENT_LAWFIRM'] = data['AGENT_ATTORNEY_LAW_FIRM_BUSINESS_NAME'].apply(lambda x : company_name_replace(x,2))\n",
    "    \n",
    "    stem_list = set(pd.read_excel('stem.xlsx')['OCC_CODE'])\n",
    "    data['STEM'] = data['SOC_CODE'].apply(lambda x : 1 if x in stem_list else 0)\n",
    "    data['SOC_CODE'] = data['SOC_CODE'].apply(lambda x : \"SOC \" + clean_code(x))\n",
    "    \n",
    "    data = data.drop(columns = ['CASE_NUMBER','WAGE_UNIT','WAGE1','WORKSITE_CITY_1','WORKSITE_STATE_1','WORKSITE_POSTAL_CODE_1',\n",
    "                                'WAGE2','PW_UNIT_OF_PAY_1','PW_UNIT','PREVAILING_WAGE_1',\n",
    "                               'WAGE_RATE_OF_PAY_FROM_1','WAGE_RATE_OF_PAY_TO_1','WAGE_UNIT_OF_PAY_1','EMPLOYER_NAME','AGENT_ATTORNEY_LAW_FIRM_BUSINESS_NAME','PW_WAGE_LEVEL_1','PW_OES_YEAR_1','PW_OTHER_SOURCE_1',\n",
    "                               'WAGE1_HOURLY_RATE','WAGE2_HOURLY_RATE','ANNUAL_PW_RATE'])\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "file = 'Data/Final/FY2019.csv'\n",
    "filename = file.split('/')[-1]\n",
    "df = pd.read_csv(file, usecols = use_columns_2019, parse_dates=['DECISION_DATE'])\n",
    "clean_data_2019(df).to_csv(os.path.join(os.getcwd(),'Download/',filename), index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_20182017(data):\n",
    " \n",
    "    data['DECISION_DATE'] = data['DECISION_DATE'].dt.date\n",
    "    data['CASE_STATUS'] = data['CASE_STATUS'].str.lower().str.title()\n",
    "    data = data[(data['CASE_STATUS'] == \"Certified\") & ((data['VISA_CLASS']== 'H-1B')| (data['VISA_CLASS']== 'H-1B1 Chile')| (data['VISA_CLASS']== 'H-1B1 Singapore'))].drop_duplicates(subset=['CASE_NUMBER'])\n",
    "    \n",
    "    for x in ['EMPLOYER_NAME','AGENT_ATTORNEY_NAME','WORKSITE_CITY','WORKSITE_STATE','WORKSITE_POSTAL_CODE','JOB_TITLE','PW_WAGE_LEVEL',\n",
    "             'PW_SOURCE_YEAR','PW_SOURCE']:\n",
    "        data[x] = data[x].fillna('No Info')\n",
    "\n",
    "\n",
    "    data['SOC_CODE'] = data['SOC_CODE'].apply(lambda x : clean_code(x))\n",
    "    data['SOC_TITLE'] = data['SOC_NAME'].apply(lambda x : clean_title(x))\n",
    "    data['NAICS_CODE'] = data['NAICS_CODE'].apply(lambda x : clean_code(str(x)) )   \n",
    "    data['WORKSITE_STATE'] = data['WORKSITE_STATE'].apply(lambda x : get_state_abbrev(x))\n",
    "    data['WORKSITE_CITY'] = data['WORKSITE_CITY'].apply(lambda x : clean_city(x))\n",
    "    data['WORKSITE_POSTAL_CODE'] = data['WORKSITE_POSTAL_CODE'].apply(lambda x : clean_zip_code(x))   \n",
    "    data['WORKSITE_POSTAL_CODE'] = data['WORKSITE_POSTAL_CODE'].str.zfill(5)\n",
    "    \n",
    "    data['WAGE_UNIT'] =  data['WAGE_UNIT_OF_PAY'].apply(lambda x : get_wage_unit(x))\n",
    "    data['WAGE1_HOURLY_RATE'] = data['WAGE_RATE_OF_PAY_FROM'] / data['WAGE_UNIT']\n",
    "    data['WAGE2_HOURLY_RATE'] = data['WAGE_RATE_OF_PAY_TO'] / data['WAGE_UNIT']    \n",
    "    data['WAGE1'] = data['WAGE1_HOURLY_RATE'].apply(lambda x: get_hourly_wage(x) * 2080)\n",
    "    data['WAGE2'] = data['WAGE1_HOURLY_RATE'].apply(lambda x: get_hourly_wage(x) *2080)\n",
    "    data['ANNUAL_WAGE'] = data['WAGE2'] if data['WAGE1'].empty else data['WAGE1'] \n",
    "    \n",
    "    data['PW_UNIT'] = data['PW_UNIT_OF_PAY'].apply(lambda x : get_wage_unit(x))\n",
    "    data['ANNUAL_PW_RATE'] = data['PREVAILING_WAGE'] / data['PW_UNIT']\n",
    "    data['ANNUAL_PW'] = data['ANNUAL_PW_RATE'].apply(lambda x : get_hourly_wage(x) * 2080) \n",
    "    \n",
    "    \n",
    "    data['JOB_TITLE'] = data['JOB_TITLE'].apply(lambda x : clean_title(x))\n",
    "    data['EMPLOYER'] = data['EMPLOYER_NAME'].apply(lambda x : company_name_replace(x,2))\n",
    "    data['EMPLOYER_2'] = data['EMPLOYER'] .apply(lambda x: 'Amazon' if 'Amazon' in x else x)\n",
    "    data['AGENT_LAWFIRM'] = data['AGENT_ATTORNEY_NAME'].apply(lambda x : company_name_replace(x,2))\n",
    "    \n",
    "    stem_list = set(pd.read_excel('stem.xlsx')['OCC_CODE'])\n",
    "    data['STEM'] = data['SOC_CODE'].apply(lambda x : 1 if x in stem_list else 0)\n",
    "    data['SOC_CODE'] = data['SOC_CODE'].apply(lambda x : \"SOC \" + clean_code(x))\n",
    "    \n",
    "    data = data.drop(columns = ['CASE_NUMBER','WAGE_UNIT','WAGE1','SOC_NAME',\n",
    "                                'WAGE2','PW_UNIT_OF_PAY','PW_UNIT','PREVAILING_WAGE',\n",
    "                               'WAGE_RATE_OF_PAY_FROM','WAGE_RATE_OF_PAY_TO','WAGE_UNIT_OF_PAY','EMPLOYER_NAME','AGENT_ATTORNEY_NAME',\n",
    "                               'WAGE1_HOURLY_RATE','WAGE2_HOURLY_RATE','ANNUAL_PW_RATE'])\n",
    "\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "for file in glob.glob('Data/Final/FY201*.csv'):\n",
    "    if file.split('/')[-1].split('.')[0][2:] in ['2017', '2018']:\n",
    "        filename = file.split('/')[-1]\n",
    "        df = pd.read_csv(file, usecols = use_columns_20182017,parse_dates=['DECISION_DATE'])\n",
    "        clean_data_20182017(df).to_csv(os.path.join(os.getcwd(),'Download/',filename), index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
